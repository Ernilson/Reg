package br.com.menu.service;

import br.com.menu.repository.VectorRepository;
import br.com.menu.repository.ChatMemoryRepository;
import lombok.RequiredArgsConstructor;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.stereotype.Service;

import java.util.*;
import java.util.stream.Collectors;

@Service
@RequiredArgsConstructor
public class RagService {

    private final EmbeddingService embeddingService;
    private final VectorRepository vectorRepository;
    private final OllamaService ollamaService;

    // üîπ NOVO: mem√≥ria
    private final ChatMemoryRepository chatMemoryRepository;

    @Value("${rag.top-k:5}")
    private int topK;

    @Value("${rag.threshold:0.6}")
    private double threshold;

    @Value("${rag.max-context-chars:4000}")
    private int maxContextChars;

    @Value("${rag.max-chunks-per-source:2}")
    private int maxChunksPerSource;

    // üîπ NOVO: quantas mensagens puxar da mem√≥ria
    @Value("${rag.memory.last-n:10}")
    private int memoryLastN;

    public RagAnswer ask(String sessionId, String question) {

        if (sessionId == null || sessionId.isBlank()) {
            sessionId = "default";
        }

        // 0Ô∏è‚É£ Salva pergunta do usu√°rio na mem√≥ria
        chatMemoryRepository.add(UUID.randomUUID(), sessionId, "user", question);

        // 1Ô∏è‚É£ Embedding
        var qVec = embeddingService.generateEmbedding(question);

        // 2Ô∏è‚É£ Busca vetorial
        var results = vectorRepository.searchTopK(qVec, topK, threshold);

        // 3Ô∏è‚É£ Ordena por relev√¢ncia (distance)
        var sortedByRelevance = results.stream()
                .sorted(Comparator.comparingDouble(VectorRepository.SearchResult::distance))
                .toList();

        // 4Ô∏è‚É£ Filtra por threshold + limita por source
        var limitedPerSource = sortedByRelevance.stream()
                .filter(r -> r.distance() <= threshold)
                .collect(Collectors.groupingBy(
                        VectorRepository.SearchResult::source,
                        LinkedHashMap::new,
                        Collectors.collectingAndThen(
                                Collectors.toList(),
                                list -> list.stream()
                                        .limit(maxChunksPerSource)
                                        .toList()
                        )
                ))
                .values()
                .stream()
                .flatMap(List::stream)
                .toList();

        // 5Ô∏è‚É£ Remove duplica√ß√£o por conte√∫do
        var unique = limitedPerSource.stream()
                .collect(Collectors.collectingAndThen(
                        Collectors.toMap(
                                VectorRepository.SearchResult::content,
                                r -> r,
                                (r1, r2) -> r1,
                                LinkedHashMap::new
                        ),
                        m -> new ArrayList<>(m.values())
                ));

        // 6Ô∏è‚É£ REORDENA POR CHUNK_INDEX (Para manter a ordem l√≥gica do texto)
        unique.sort(Comparator.comparingInt(VectorRepository.SearchResult::chunkIndex));

        // 7Ô∏è‚É£ Monta contexto com limite de tamanho
        StringBuilder contextBuilder = new StringBuilder();

        for (var r : unique) {
            String chunk = """
                    [Documento: %s | p√°g: %s | chunk: %s]
                    %s

                    """.formatted(
                    r.source(),
                    r.page(),
                    r.content(),       // se seu SearchResult ainda n√£o tem page, remove aqui
                    r.chunkIndex(),
                    r.content()
            );

            if (contextBuilder.length() + chunk.length() > maxContextChars) {
                break;
            }

            contextBuilder.append(chunk);
        }

        String context = contextBuilder.toString();

        // üîπ 7.1Ô∏è‚É£ Carrega mem√≥ria da conversa (√∫ltimas N mensagens)
        var memoryDesc = chatMemoryRepository.lastMessages(sessionId, memoryLastN);

        // vem DESC -> reverte pra ficar cronol√≥gico no prompt
        var memory = new ArrayList<>(memoryDesc);
        Collections.reverse(memory);

        String memoryText = memory.stream()
                .map(m -> m.role() + ": " + m.content())
                .collect(Collectors.joining("\n"));

        // 8Ô∏è‚É£ Prompt (RAG + mem√≥ria)
        String prompt = """
Voc√™ √© um assistente chamado "amigo".

Regras:
1) Se a PERGUNTA for sobre identidade do assistente, sauda√ß√£o, prefer√™ncias, ou continua√ß√£o de conversa (ex: "qual √© seu nome?"), responda normalmente usando a MEM√ìRIA, mesmo que o CONTEXTO esteja vazio.
2) Se a PERGUNTA exigir fatos dos DOCUMENTOS, use APENAS o CONTEXTO do RAG como fonte.
3) Se a informa√ß√£o n√£o estiver no CONTEXTO para perguntas que dependem de documentos, responda: "N√£o encontrei essa informa√ß√£o no documento."
4) Seja claro e direto.

MEM√ìRIA (conversa):
%s

CONTEXTO (documentos):
%s

Pergunta: %s

Resposta:
""".formatted(memoryText, context, question);

        // 9Ô∏è‚É£ Gera√ß√£o
        String answer = ollamaService.generate(prompt);

        // üîü Salva resposta do assistente na mem√≥ria
        chatMemoryRepository.add(UUID.randomUUID(), sessionId, "assistant", answer);

        return new RagAnswer(answer, unique);
    }

    public record RagAnswer(String answer,
                            List<VectorRepository.SearchResult> sources) {}
}
