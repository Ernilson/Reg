

embedding model: nomic-embed-text â†’ normalmente retorna vetor 768 dimensÃµes.
EntÃ£o o VECTOR(768)

CREATE EXTENSION IF NOT EXISTS vector;

CREATE TABLE IF NOT EXISTS documents (
  id UUID PRIMARY KEY,
  source TEXT,
  content TEXT NOT NULL,
  embedding VECTOR(768) NOT NULL,
  created_at TIMESTAMP DEFAULT now()
);

-- Ã­ndice para busca vetorial (cosine)
CREATE INDEX IF NOT EXISTS idx_documents_embedding
ON documents USING hnsw (embedding vector_cosine_ops);
------------------------------------------------------------
modelo leve
docker exec -it ollama ollama pull phi3

o modelo de embeddings no Ollama
docker exec -it ollama ollama pull nomic-embed-text

# ğŸš€ RAG Local com Spring Boot + Ollama + PostgreSQL (pgvector)

Projeto experimental de arquitetura RAG (Retrieval Augmented Generation) rodando 100% local, utilizando:

- Java 17
- Spring Boot 3
- PostgreSQL + pgvector
- Ollama (LLM local)
- WSL2 + Docker Desktop

---

# ğŸ“Œ Status Atual do Ambiente

Infraestrutura validada com sucesso:

- âœ” Docker Desktop funcionando
- âœ” WSL2 configurado com memÃ³ria adequada
- âœ” PostgreSQL com extensÃ£o pgvector ativo
- âœ” Ollama rodando em container
- âœ” Modelo LLM carregado (phi3)
- âœ” API do Ollama respondendo corretamente

---

# ğŸ— Arquitetura Atual

Windows
â””â”€â”€ WSL2
â””â”€â”€ Docker Desktop
â”œâ”€â”€ PostgreSQL + pgvector
â””â”€â”€ Ollama (LLM local)

AplicaÃ§Ã£o Spring Boot conecta:

- PostgreSQL â†’ armazenamento vetorial
- Ollama â†’ geraÃ§Ã£o de respostas e embeddings

---

# ğŸ³ Docker

Containers ativos:

- `rag-postgres`
- `ollama`

Verificar containers:

```bash
docker ps

WSL2 ConfiguraÃ§Ã£o de MemÃ³ria

Arquivo:

C:\Users\<seu-usuario>\.wslconfig


ConteÃºdo utilizado:

[wsl2]
memory=10GB
processors=4
swap=4GB


ReinÃ­cio aplicado com:

wsl --shutdown


ValidaÃ§Ã£o:

docker info


Resultado esperado:

Total Memory: ~8GB ou mais

ğŸ¤– Ollama

Modelo carregado:

phi3


Download do modelo:

docker exec -it ollama ollama pull phi3

ğŸ” Teste direto da API Ollama
curl http://localhost:11434/api/generate -d '{
  "model": "phi3",
  "prompt": "Explique o que Ã© RAG em poucas palavras",
  "stream": false
}'


Resposta esperada:

{
  "model": "phi3",
  "response": "...",
  "done": true
}

ğŸ“¡ API Spring Boot

AplicaÃ§Ã£o iniciada com:

mvn spring-boot:run


Endpoint validado:

POST /rag/ask
